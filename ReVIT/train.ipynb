{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from dataset import data_loader\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = \"../data/TB_data/\"\n",
    "\n",
    "# define data loader\n",
    "def data_loader(root_dir, image_size=(224, 224), batch_size=30, train_dir='training', test_dir='testing', vald_dir='validation'):\n",
    "    dirs = {'train': os.path.join(root_dir, train_dir),\n",
    "            'valid': os.path.join(root_dir, vald_dir),\n",
    "            'test': os.path.join(root_dir, test_dir)}\n",
    "\n",
    "    data_transform = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            transforms.ToTensor()\n",
    "        ]),\n",
    "\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor()\n",
    "        ]),\n",
    "\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_dataset = {x: ImageFolder(dirs[x], transform=data_transform[x])\n",
    "                     for x in ('train', 'valid', 'test')}\n",
    "\n",
    "    data_loaders = {x: DataLoader(image_dataset[x], batch_size=batch_size,\n",
    "                                   shuffle=True, num_workers=12) for x in ['train']}\n",
    "\n",
    "    data_loaders['test'] = DataLoader(image_dataset['test'], batch_size=batch_size,\n",
    "                                       shuffle=False, num_workers=12, drop_last=True)\n",
    "\n",
    "    data_loaders['valid'] = DataLoader(image_dataset['valid'], batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=12, drop_last=True)\n",
    "\n",
    "    dataset_size = {x: len(image_dataset[x]) for x in ['train', 'valid', 'test']}\n",
    "\n",
    "    print([f'number of {i} images is {dataset_size[i]}' for i in (dataset_size)])\n",
    "\n",
    "    class_idx = image_dataset['test'].class_to_idx\n",
    "    print(f'Classes with index are: {class_idx}')\n",
    "\n",
    "    class_names = image_dataset['test'].classes\n",
    "    print(class_names)\n",
    "    return data_loaders, image_dataset\n",
    "\n",
    "\n",
    "# train the model  \n",
    "def train_on_images(model, dataloader, criterion, optimizer, num_epochs=10, device='cuda', savePth='model.pth'):\n",
    "    model.to(device)\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(dataloader['train']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(dataloader['train'].dataset)\n",
    "        print(f\"Epoch {epoch+1} - Train Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # validate\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader['valid']:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss /= len(dataloader['valid'].dataset)\n",
    "        print(f\"Epoch {epoch+1} - Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # save best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            if savePth != None:\n",
    "                torch.save(model, savePth)\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    if savePth != None:\n",
    "        print(f\"Best model saved at {savePth}\")\n",
    "    return model\n",
    "\n",
    "# def train_on_patches(model, dataloader, criterion, optimizer, vit_model, num_epochs=10, device='cuda', savePth='model.pth'):\n",
    "#     model.to(device)\n",
    "#     best_loss = float('inf')\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "#         print(\"-\" * 10)\n",
    "#         running_loss = 0.0\n",
    "#         for inputs, labels in tqdm(dataloader['train']):\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             x = vit_model.patch_embed(inputs)\n",
    "#             x = vit_model.pos_drop(x)\n",
    "#             for block in vit_model.blocks:\n",
    "#                 x = block(x)\n",
    "#             outputs = model(x)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#         epoch_loss = running_loss / len(dataloader['train'].dataset)\n",
    "#         print(f\"Epoch {epoch+1} - Train Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "#         # validate\n",
    "#         val_loss = 0.0\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in dataloader['valid']:\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "#                 x = vit_model.patch_embed(inputs)\n",
    "#                 x = vit_model.pos_drop(x)\n",
    "#                 for block in vit_model.blocks:\n",
    "#                     x = block(x)\n",
    "#                 outputs = model(x)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item() * inputs.size(0)\n",
    "#         val_loss /= len(dataloader['valid'].dataset)\n",
    "#         print(f\"Epoch {epoch+1} - Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "#         # Release unused memory\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "#         # save best model\n",
    "#         if val_loss < best_loss:\n",
    "#             best_loss = val_loss\n",
    "#             if savePth != None:\n",
    "#                 torch.save(model, savePth)\n",
    "        \n",
    "#         model.train()\n",
    "\n",
    "#     print(\"Training complete!\")\n",
    "#     if savePth != None:\n",
    "#         print(f\"Best model saved at {savePth}\")\n",
    "#     return model\n",
    "\n",
    "def train_on_patches(model, dataloader, criterion, optimizer, vit_model, clf, num_epochs=10, device='cuda', savePth='model.pth'):\n",
    "    model.to(device)\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(dataloader['train']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x = vit_model.patch_embed(inputs)\n",
    "            x = vit_model.pos_drop(x)\n",
    "            for block in range(clf):\n",
    "                x = vit_model.blocks[block](x)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(dataloader['train'].dataset)\n",
    "        print(f\"Epoch {epoch+1} - Train Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # validate\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader['valid']:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                x = vit_model.patch_embed(inputs)\n",
    "                x = vit_model.pos_drop(x)\n",
    "                for block in range(clf):\n",
    "                    x = vit_model.blocks[block](x)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss /= len(dataloader['valid'].dataset)\n",
    "        print(f\"Epoch {epoch+1} - Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Release unused memory\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # save best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            if savePth != None:\n",
    "                torch.save(model, savePth)\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    if savePth != None:\n",
    "        print(f\"Best model saved at {savePth}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# test the model\n",
    "def test_on_images(model, dataloader, device='cuda'):\n",
    "    print(type(model))\n",
    "    model.eval()\n",
    "    print(\"Evaluated\")\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(dataloader['test']):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "def test_on_patches(model, dataloader, vit_model, device='cuda'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(dataloader['test']):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            x = vit_model.patch_embed(images)\n",
    "            x = vit_model.pos_drop(x)\n",
    "            for block in vit_model.blocks:\n",
    "                x = block(x)\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "def test_vit(model, dataloader_test):\n",
    "    \"\"\"\n",
    "    This function used to test ViT. \n",
    "\n",
    "    Args: \n",
    "        model: ViT model\n",
    "        dataaloader_test: loader for test images \n",
    "    return: \n",
    "        Avg test accuracy of ViT\n",
    "    \n",
    "    \"\"\"\n",
    "    test_acc = 0.0\n",
    "    for images, labels in tqdm(dataloader_test): \n",
    "        images = images.cuda()\n",
    "        labels= labels.cuda()\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            output = model(images)\n",
    "            prediction = torch.argmax(output, dim=-1)\n",
    "            acc = sum(prediction == labels).float().item()/len(labels)\n",
    "            test_acc += acc\n",
    "    print(f'Testing accuracy = {(test_acc/len(dataloader_test)):.4f}')\n",
    "\n",
    "    return round(test_acc/len(dataloader_test),2)\n",
    "\n",
    "\n",
    "def test_all_classifiers(classifiers_list, dataloader_test, mlp_root_dir, vit_model):\n",
    "    for clf in range(1, len(classifiers_list) +1):\n",
    "        acc_avg = 0.0\n",
    "        print(classifiers_list[clf-1])\n",
    "        clf_in = torch.load(os.path.join(mlp_root_dir, classifiers_list[clf-1])).cuda()\n",
    "        clf_in.eval()\n",
    "        # print(clf_in)\n",
    "        print(f'Classifier of index {clf-1} has been loaded')\n",
    "\n",
    "        for images, labels in tqdm(dataloader_test): \n",
    "            images = images.cuda()\n",
    "            labels= labels.cuda()\n",
    "            # print(images.shape) #torch.Size([30, 3, 224, 224])\n",
    "            x = vit_model.patch_embed(images)\n",
    "            # print(x.shape)  #torch.Size([30, 196, 768])\n",
    "            x = vit_model.pos_drop(x)\n",
    "            # print(x.shape)  #torch.Size([30, 196, 768])\n",
    "            for block in range(clf):\n",
    "                x = vit_model.blocks[block](x)\n",
    "            # x = x.reshape(30, 3, 224, 224)\n",
    "            with torch.no_grad():\n",
    "                # print(x.shape) #torch.Size([30, 196, 768])\n",
    "                output = clf_in(x)\n",
    "            predictions = torch.argmax(output, dim=-1)\n",
    "            acc = torch.sum(predictions == labels).item()/len(labels)\n",
    "            acc_avg += acc\n",
    "        print(f'Accuracy of block {clf-1} = {(acc_avg/len(dataloader_test)):.3f}')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countParams(model):\n",
    "    total_params = sum(param.numel() for param in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Total Params: \", total_params)\n",
    "    print(\"Trainable Params: \", trainable_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of train images is 5670', 'number of valid images is 630', 'number of test images is 700']\n",
      "Classes with index are: {'Normal': 0, 'Tuberculosis': 1}\n",
      "['Normal', 'Tuberculosis']\n",
      "\n",
      "\n",
      "mlp  0 :\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [02:27<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 24.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Validation Loss: 0.6844\n",
      "Training complete!\n",
      "Best model saved at ../ReVIT/models/MyModels2/mlp_block_0.pth\n"
     ]
    }
   ],
   "source": [
    "# train_on_Patches mlps\n",
    "import mlp as mlp\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load data\n",
    "loader_, dataset_ = data_loader(root_dir=root_dir)\n",
    "\n",
    "vit_model = torch.load('../models/vit_base_patch16_224_in21k_test-accuracy_0.96_chest.pth')\n",
    "\n",
    "# # Train 5 mlp models and save it\n",
    "for i in range(1):\n",
    "    print(\"\\n\\nmlp \", i, \":\")\n",
    "    mlp_in = mlp.Classifier()\n",
    "    optimizer_mlp = optim.Adam(mlp_in.parameters(), lr=0.001)\n",
    "    model_mlp = train_on_patches(mlp_in, loader_, criterion, optimizer_mlp, vit_model=vit_model, clf=5, num_epochs=1, savePth=\"../ReVIT/models/MyModels2/mlp_block_\"+ str(i) +\".pth\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_on_images r_mlps\n",
    "import random_mlp as random_mlp\n",
    "import random\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load datamlp_in\n",
    "loader_, dataset_ = data_loader(root_dir=root_dir)\n",
    "\n",
    "# # Train 5 mlp models and save it\n",
    "for i in range(5):\n",
    "    print(\"\\n\\nmlp \", i, \":\")\n",
    "    r_mlp = random_mlp.Classifier(num_layers=random.randint(4,10))\n",
    "    optimizer_mlp = optim.Adam(r_mlp.parameters(), lr=0.001)\n",
    "    model_mlp = train_on_images(r_mlp, loader_, criterion, optimizer_mlp, num_epochs=5, savePth=\"../ReVIT/models/R_Models/random_mlp\"+ str(i) +\".pth\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_mlp1.pth\n",
      "Total Params:  627753026\n",
      "Trainable Params:  627753026\n",
      "random_mlp0.pth\n",
      "Total Params:  627712258\n",
      "Trainable Params:  627712258\n",
      "random_mlp.pth\n",
      "Total Params:  316680194\n",
      "Trainable Params:  316680194\n",
      "random_mlp4.pth\n",
      "Total Params:  627753026\n",
      "Trainable Params:  627753026\n",
      "random_mlp3.pth\n",
      "Total Params:  627581442\n",
      "Trainable Params:  627581442\n",
      "random_mlp2.pth\n",
      "Total Params:  627581442\n",
      "Trainable Params:  627581442\n"
     ]
    }
   ],
   "source": [
    "model_dir = '../ReVIT/models/R_Models/'\n",
    "for i in (os.listdir(model_dir)):\n",
    "    print(i)    \n",
    "    countParams(torch.load(model_dir+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params:  627581442\n",
      "Trainable Params:  627581442\n"
     ]
    }
   ],
   "source": [
    "countParams(torch.load('../ReVIT/models/R_Models/random_mlp2.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------> random_mlp0.pth 0\n",
      "Total Params:  627712258\n",
      "Trainable Params:  627712258\n",
      "<class 'random_mlp.Classifier'>\n",
      "Evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 87 %\n",
      "\n",
      "-------------> random_mlp1.pth 1\n",
      "Total Params:  627753026\n",
      "Trainable Params:  627753026\n",
      "<class 'random_mlp.Classifier'>\n",
      "Evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 86 %\n",
      "\n",
      "-------------> random_mlp2.pth 2\n",
      "Total Params:  627581442\n",
      "Trainable Params:  627581442\n",
      "<class 'random_mlp.Classifier'>\n",
      "Evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 82 %\n",
      "\n",
      "-------------> random_mlp3.pth 3\n",
      "Total Params:  627581442\n",
      "Trainable Params:  627581442\n",
      "<class 'random_mlp.Classifier'>\n",
      "Evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 81 %\n",
      "\n",
      "-------------> random_mlp4.pth 4\n",
      "Total Params:  627753026\n",
      "Trainable Params:  627753026\n",
      "<class 'random_mlp.Classifier'>\n",
      "Evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testing_on_images r_mlp modules\n",
    "model_dir = '../ReVIT/models/R_Models/'\n",
    "for index, i in enumerate(sorted(os.listdir(model_dir))):\n",
    "    print(\"\\n------------->\", i, index)\n",
    "    model = torch.load(model_dir+i)\n",
    "    countParams(model)\n",
    "    test_on_images(model=model, dataloader=loader_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of train images is 5670', 'number of valid images is 630', 'number of test images is 700']\n",
      "Classes with index are: {'Normal': 0, 'Tuberculosis': 1}\n",
      "['Normal', 'Tuberculosis']\n",
      "Total Params:  85800194\n",
      "Trainable Params:  85800194\n",
      "\n",
      "-------------> mlp_block_0.pth 0\n",
      "Total Params:  625219970\n",
      "Trainable Params:  625219970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:06<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 49 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing_on_patches mlp modules\n",
    "model_dir = '../ReVIT/models/MyModels2/'\n",
    "loader_, dataset_ = data_loader(root_dir=root_dir)\n",
    "vit_model = torch.load('../models/vit_base_patch16_224_in21k_test-accuracy_0.96_chest.pth')\n",
    "vit_model.eval()\n",
    "countParams(vit_model)\n",
    "for index, i in enumerate(sorted(os.listdir(model_dir))):\n",
    "    print(\"\\n------------->\", i, index)\n",
    "    model = torch.load(model_dir+i)\n",
    "    countParams(model)\n",
    "    test_on_patches(model=model, dataloader=loader_, vit_model=vit_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the mlp modules through the first 5 blocks of ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params:  85800194\n",
      "Trainable Params:  85800194\n"
     ]
    }
   ],
   "source": [
    "countParams(torch.load('../models/vit_base_patch16_224_in21k_test-accuracy_0.96_chest.pth').to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of train images is 5670', 'number of valid images is 630', 'number of test images is 700']\n",
      "Classes with index are: {'Normal': 0, 'Tuberculosis': 1}\n",
      "['Normal', 'Tuberculosis']\n",
      "Total Params:  85800194\n",
      "Trainable Params:  85800194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:05<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy = 0.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"../data/TB_data/\"\n",
    "loader_, dataset_ = data_loader(root_dir=root_dir)\n",
    "vit_model = torch.load('../models/vit_base_patch16_224_in21k_test-accuracy_0.96_chest.pth')\n",
    "countParams(vit_model)\n",
    "test_vit(vit_model, loader_['test'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing pretrained mlp modules (where their input is ViT outputted patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_0_classifier_0.94test_0.98train.pth\n",
      "Classifier of index 0 has been loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of block 0 = 0.945\n",
      "block_1_classifier_0.93test_0.99train.pth\n",
      "Classifier of index 1 has been loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of block 1 = 0.933\n",
      "block_2_classifier_0.94test_0.99train.pth\n",
      "Classifier of index 2 has been loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of block 2 = 0.941\n",
      "block_3_classifier_0.93test_0.99train.pth\n",
      "Classifier of index 3 has been loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of block 3 = 0.933\n",
      "block_4_classifier_0.92test_1.00train.pth\n",
      "Classifier of index 4 has been loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of block 4 = 0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "classifiers_list = sorted(os.listdir('../models/MLP_new_chest'))\n",
    "# print(classifiers_list)\n",
    "test_classifiers(classifiers_list=classifiers_list, dataloader_test=loader_['test'], mlp_root_dir='../models/MLP_new_chest', vit_model=vit_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing trained mlp modules (where their input is ViT outputted patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_block_0.pth\n",
      "Classifier of index 0 has been loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:02<00:00, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of block 0 = 0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "classifiers_list = sorted(os.listdir('../ReVIT/models/MyModels2'))\n",
    "# print(classifiers_list)\n",
    "test_classifiers(classifiers_list=classifiers_list, dataloader_test=loader_['test'], mlp_root_dir='../ReVIT/models/MyModels2', vit_model=vit_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "89ade8f41426f99352904e8be2cf333ad690b99e026c88e03d1f284bef19dc61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
